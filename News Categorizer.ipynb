{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Getting 7000 articles for Data"
      ],
      "metadata": {
        "id": "qsgVGsXuNM3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlBnNgtbNHgz"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Your Guardian API key\n",
        "API_KEY = 'e8181f97-dcf6-4085-8f72-2fb34cb47f3e'  # replace with your actual API key\n",
        "BASE_URL = 'https://content.guardianapis.com/search'\n",
        "\n",
        "# Define the target categories and the number of articles to fetch per category\n",
        "target_categories = [\"Life and style\", \"Law\", \"Film\", \"Books\", \"Art and design\", \"Games\", \"Travel\"]\n",
        "ARTICLES_PER_CATEGORY = 1000\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "# Function to fetch articles from The Guardian API\n",
        "def fetch_articles(api_key, query, page_size=12, page=1):\n",
        "    url = BASE_URL\n",
        "    params = {\n",
        "        'q': query,\n",
        "        'api-key': api_key,\n",
        "        'show-fields': 'bodyText',  # Fetches article content\n",
        "        'page-size': page_size,\n",
        "        'page': page\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error fetching articles: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Data storage\n",
        "all_articles = []\n",
        "\n",
        "# Collect 1,000 articles for each specified category\n",
        "for category in target_categories:\n",
        "    print(f\"Gathering articles for category: {category}\")\n",
        "    category_articles = []\n",
        "    page = 1\n",
        "\n",
        "    while len(category_articles) < ARTICLES_PER_CATEGORY:\n",
        "        # Fetch a batch of articles for the chosen category\n",
        "        data = fetch_articles(API_KEY, category, page_size=BATCH_SIZE, page=page)\n",
        "        if data and 'response' in data:\n",
        "            results = data['response']['results']\n",
        "            for result in results:\n",
        "                if len(category_articles) >= ARTICLES_PER_CATEGORY:\n",
        "                    break  # Stop if we have 1,000 articles for this category\n",
        "\n",
        "                # Store the article content and assign the specific category\n",
        "                article = {\n",
        "                    'category': category,\n",
        "                    'content': result['fields'].get('bodyText', '')\n",
        "                }\n",
        "                category_articles.append(article)\n",
        "\n",
        "            # Pause for 1 second after each batch of 12 articles\n",
        "            time.sleep(1)\n",
        "            print(len(category_articles))\n",
        "\n",
        "        # Move to the next page for more results\n",
        "        page += 1\n",
        "\n",
        "    # Add articles from this category to the main list\n",
        "    all_articles.extend(category_articles)\n",
        "    print(f\"Collected {len(category_articles)} articles for category: {category}\")\n",
        "\n",
        "# Convert list of articles to a DataFrame\n",
        "df = pd.DataFrame(all_articles)\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df.to_csv('guardian_articles_7000.csv', index=False)\n",
        "\n",
        "# Display first few rows of the DataFrame\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting the articles in each category"
      ],
      "metadata": {
        "id": "khSPixPjNcWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('guardian_articles_7000.csv')\n",
        "\n",
        "# Count the occurrences of each category in the 'category' column\n",
        "category_counts = df['category'].value_counts()\n",
        "\n",
        "# Display the result\n",
        "print(category_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8vZXAnnNiO6",
        "outputId": "91516576-f34a-4601-fdba-ace26b0c4616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "Life and style    1000\n",
            "Law               1000\n",
            "Film              1000\n",
            "Books             1000\n",
            "Art and design    1000\n",
            "Games             1000\n",
            "Travel            1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode the article content"
      ],
      "metadata": {
        "id": "vBmJB7YTO217"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def process_text(text):\n",
        "\n",
        "    # Check if text is not a string\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Return empty string or you could use return None\n",
        "\n",
        "    # Define punctuation to remove\n",
        "    punctuation_extended = string.punctuation + \"‘’“”!@#$%^&*()`~-_=+[]{}\\|:;<>,.?/–...\"  # add specific quote characters\n",
        "\n",
        "    # Remove punctuation\n",
        "    translator = str.maketrans('', '', punctuation_extended)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "\n",
        "    # Return processed text\n",
        "    return \" \".join(stemmed_tokens)\n",
        "\n",
        "df = pd.read_csv('guardian_articles_7000.csv')\n",
        "\n",
        "df['content'] = df['content'].apply(process_text)\n",
        "\n",
        "df.to_csv('guardian_articles_encoded.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCyqwQKBO7BZ",
        "outputId": "0be98507-4f24-4a6a-e25e-f9819d6d5538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply count vectorization to the encoded file"
      ],
      "metadata": {
        "id": "yOgEbY3SQ4yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import gc  # For manual garbage collection\n",
        "import time\n",
        "\n",
        "# Load the CSV file (adjust the file path as needed)\n",
        "file_path = 'guardian_articles_encoded.csv'  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove rows where 'processed_content' has NaN values\n",
        "df = df.dropna(subset=['content'])\n",
        "\n",
        "# Initialize the vectorizers with limited features (fitting on the entire dataset)\n",
        "count_vectorizer = CountVectorizer(max_features=5000, max_df=0.8, min_df=10)\n",
        "\n",
        "# Fit both vectorizers on the entire 'processed_content' column to fix vocabulary\n",
        "count_vectorizer.fit(df['content'])\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1000  # Adjust batch size based on available memory\n",
        "\n",
        "# Create an empty list to store vectorized results\n",
        "all_batches = []\n",
        "\n",
        "# Process the data in batches to control memory usage\n",
        "for i in range(0, len(df), batch_size):\n",
        "    print(f\"Processing batch {i // batch_size + 1}\")\n",
        "\n",
        "    # Get the batch of data\n",
        "    batch_df = df[i:i + batch_size]\n",
        "\n",
        "    # Apply Count Vectorization on the batch (sparse matrix)\n",
        "    count_matrix = count_vectorizer.transform(batch_df['content'])\n",
        "\n",
        "    # Convert to DataFrame (with column prefixes to distinguish)\n",
        "    count_df = pd.DataFrame(count_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Add prefix to distinguish TF-IDF and Count columns\n",
        "    count_df = count_df.add_prefix('count_')\n",
        "\n",
        "    # Join the vectorized data with the original batch dataframe\n",
        "    batch_result = batch_df.reset_index(drop=True).join(count_df)\n",
        "\n",
        "    # Append the result to the final list\n",
        "    all_batches.append(batch_result)\n",
        "\n",
        "    # Clear memory of the matrices after processing each batch\n",
        "    del count_matrix, count_df\n",
        "    gc.collect()  # Manually trigger garbage collection\n",
        "\n",
        "    # Adding sleep time to control system resources if needed\n",
        "    time.sleep(1)  # Adjust sleep duration based on your system\n",
        "\n",
        "# Concatenate all processed batches into a single DataFrame\n",
        "final_df = pd.concat(all_batches, ignore_index=True)\n",
        "\n",
        "# Save the final DataFrame with vectorized columns to a CSV file\n",
        "output_file = 'guardian_articles_count.csv'\n",
        "final_df.to_csv(output_file, index=False)\n",
        "\n",
        "# Display the first few rows of the new DataFrame to ensure it worked correctly\n",
        "final_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "EqdFemN6Q-ZP",
        "outputId": "a526e8b7-36bd-4557-d79f-edc4f319df59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 1\n",
            "Processing batch 2\n",
            "Processing batch 3\n",
            "Processing batch 4\n",
            "Processing batch 5\n",
            "Processing batch 6\n",
            "Processing batch 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         category                                            content  \\\n",
              "0  Life and style  orchard offer bounti appl autumn last year wen...   \n",
              "1  Life and style  born bologna either 1639 1643 sourc conflict a...   \n",
              "2  Life and style  victoria embank central london bench overlook ...   \n",
              "3  Life and style  letizia battaglia took pictur distanc punch ca...   \n",
              "4  Life and style  mexico love pork well document countri influen...   \n",
              "\n",
              "   count_00  count_10  count_100  count_1000  count_10000  count_100000  \\\n",
              "0         0         2          0           0            0             0   \n",
              "1         0         0          0           0            0             0   \n",
              "2         0         0          0           0            0             1   \n",
              "3         0         0          0           0            0             0   \n",
              "4         0         3          0           0            0             0   \n",
              "\n",
              "   count_100m  count_10m  ...  count_youngest  count_your  count_youth  \\\n",
              "0           0          0  ...               0           0            0   \n",
              "1           0          0  ...               0           0            0   \n",
              "2           0          0  ...               0           1            0   \n",
              "3           0          0  ...               0           0            0   \n",
              "4           0          0  ...               0           0            0   \n",
              "\n",
              "   count_youtub  count_youv  count_zealand  count_zelenskiy  count_zero  \\\n",
              "0             0           0              0                0           0   \n",
              "1             0           0              0                0           0   \n",
              "2             0           0              0                0           0   \n",
              "3             0           0              0                0           0   \n",
              "4             0           0              0                0           0   \n",
              "\n",
              "   count_zone  count_zoom  \n",
              "0           0           0  \n",
              "1           0           0  \n",
              "2           0           1  \n",
              "3           0           0  \n",
              "4           0           0  \n",
              "\n",
              "[5 rows x 5002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8422a85d-bdc5-491b-80fb-04955eb6c796\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>count_00</th>\n",
              "      <th>count_10</th>\n",
              "      <th>count_100</th>\n",
              "      <th>count_1000</th>\n",
              "      <th>count_10000</th>\n",
              "      <th>count_100000</th>\n",
              "      <th>count_100m</th>\n",
              "      <th>count_10m</th>\n",
              "      <th>...</th>\n",
              "      <th>count_youngest</th>\n",
              "      <th>count_your</th>\n",
              "      <th>count_youth</th>\n",
              "      <th>count_youtub</th>\n",
              "      <th>count_youv</th>\n",
              "      <th>count_zealand</th>\n",
              "      <th>count_zelenskiy</th>\n",
              "      <th>count_zero</th>\n",
              "      <th>count_zone</th>\n",
              "      <th>count_zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>orchard offer bounti appl autumn last year wen...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>born bologna either 1639 1643 sourc conflict a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>victoria embank central london bench overlook ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>letizia battaglia took pictur distanc punch ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>mexico love pork well document countri influen...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5002 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8422a85d-bdc5-491b-80fb-04955eb6c796')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8422a85d-bdc5-491b-80fb-04955eb6c796 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8422a85d-bdc5-491b-80fb-04955eb6c796');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-61d294a8-97b8-481c-a8a0-a76bc03d6b2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61d294a8-97b8-481c-a8a0-a76bc03d6b2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-61d294a8-97b8-481c-a8a0-a76bc03d6b2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply tf-idf vectorization to the encoded file"
      ],
      "metadata": {
        "id": "OBdbkieCRvX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gc  # For manual garbage collection\n",
        "import time\n",
        "\n",
        "# Load the CSV file (adjust the file path as needed)\n",
        "file_path = 'guardian_articles_encoded.csv'  # Replace with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove rows where 'content' has NaN values\n",
        "df = df.dropna(subset=['content'])\n",
        "\n",
        "# Initialize the TF-IDF vectorizer with limited features (fitting on the entire dataset)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, max_df=0.8, min_df=10)\n",
        "\n",
        "# Fit the vectorizer on the entire 'content' column to fix vocabulary\n",
        "tfidf_vectorizer.fit(df['content'])\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1000  # Adjust batch size based on available memory\n",
        "\n",
        "# Create an empty list to store vectorized results\n",
        "all_batches = []\n",
        "\n",
        "# Process the data in batches to control memory usage\n",
        "for i in range(0, len(df), batch_size):\n",
        "    print(f\"Processing batch {i // batch_size + 1}\")\n",
        "\n",
        "    # Get the batch of data\n",
        "    batch_df = df[i:i + batch_size]\n",
        "\n",
        "    # Apply TF-IDF Vectorization on the batch (sparse matrix)\n",
        "    tfidf_matrix = tfidf_vectorizer.transform(batch_df['content'])\n",
        "\n",
        "    # Convert to DataFrame (with column prefixes to distinguish)\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Add prefix to distinguish TF-IDF columns\n",
        "    tfidf_df = tfidf_df.add_prefix('tfidf_')\n",
        "\n",
        "    # Join the vectorized data with the original batch dataframe\n",
        "    batch_result = batch_df.reset_index(drop=True).join(tfidf_df)\n",
        "\n",
        "    # Append the result to the final list\n",
        "    all_batches.append(batch_result)\n",
        "\n",
        "    # Clear memory of the matrices after processing each batch\n",
        "    del tfidf_matrix, tfidf_df\n",
        "    gc.collect()  # Manually trigger garbage collection\n",
        "\n",
        "    # Adding sleep time to control system resources if needed\n",
        "    time.sleep(1)  # Adjust sleep duration based on your system\n",
        "\n",
        "# Concatenate all processed batches into a single DataFrame\n",
        "final_df = pd.concat(all_batches, ignore_index=True)\n",
        "\n",
        "# Save the final DataFrame with vectorized columns to a CSV file\n",
        "output_file = 'guardian_articles_tfidf.csv'\n",
        "final_df.to_csv(output_file, index=False)\n",
        "\n",
        "# Display the first few rows of the new DataFrame to ensure it worked correctly\n",
        "final_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "npaKwGhLRzU_",
        "outputId": "348b8cfb-4f15-49ad-af51-a4150e94199d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 1\n",
            "Processing batch 2\n",
            "Processing batch 3\n",
            "Processing batch 4\n",
            "Processing batch 5\n",
            "Processing batch 6\n",
            "Processing batch 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         category                                            content  \\\n",
              "0  Life and style  orchard offer bounti appl autumn last year wen...   \n",
              "1  Life and style  born bologna either 1639 1643 sourc conflict a...   \n",
              "2  Life and style  victoria embank central london bench overlook ...   \n",
              "3  Life and style  letizia battaglia took pictur distanc punch ca...   \n",
              "4  Life and style  mexico love pork well document countri influen...   \n",
              "\n",
              "   tfidf_00  tfidf_10  tfidf_100  tfidf_1000  tfidf_10000  tfidf_100000  \\\n",
              "0       0.0  0.029125        0.0         0.0          0.0      0.000000   \n",
              "1       0.0  0.000000        0.0         0.0          0.0      0.000000   \n",
              "2       0.0  0.000000        0.0         0.0          0.0      0.033525   \n",
              "3       0.0  0.000000        0.0         0.0          0.0      0.000000   \n",
              "4       0.0  0.055213        0.0         0.0          0.0      0.000000   \n",
              "\n",
              "   tfidf_100m  tfidf_10m  ...  tfidf_youngest  tfidf_your  tfidf_youth  \\\n",
              "0         0.0        0.0  ...             0.0     0.00000          0.0   \n",
              "1         0.0        0.0  ...             0.0     0.00000          0.0   \n",
              "2         0.0        0.0  ...             0.0     0.01807          0.0   \n",
              "3         0.0        0.0  ...             0.0     0.00000          0.0   \n",
              "4         0.0        0.0  ...             0.0     0.00000          0.0   \n",
              "\n",
              "   tfidf_youtub  tfidf_youv  tfidf_zealand  tfidf_zelenskiy  tfidf_zero  \\\n",
              "0           0.0         0.0            0.0              0.0         0.0   \n",
              "1           0.0         0.0            0.0              0.0         0.0   \n",
              "2           0.0         0.0            0.0              0.0         0.0   \n",
              "3           0.0         0.0            0.0              0.0         0.0   \n",
              "4           0.0         0.0            0.0              0.0         0.0   \n",
              "\n",
              "   tfidf_zone  tfidf_zoom  \n",
              "0         0.0    0.000000  \n",
              "1         0.0    0.000000  \n",
              "2         0.0    0.032068  \n",
              "3         0.0    0.000000  \n",
              "4         0.0    0.000000  \n",
              "\n",
              "[5 rows x 5002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07f87f5d-5ecf-4e13-b5b7-c0e363ec9e20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "      <th>tfidf_00</th>\n",
              "      <th>tfidf_10</th>\n",
              "      <th>tfidf_100</th>\n",
              "      <th>tfidf_1000</th>\n",
              "      <th>tfidf_10000</th>\n",
              "      <th>tfidf_100000</th>\n",
              "      <th>tfidf_100m</th>\n",
              "      <th>tfidf_10m</th>\n",
              "      <th>...</th>\n",
              "      <th>tfidf_youngest</th>\n",
              "      <th>tfidf_your</th>\n",
              "      <th>tfidf_youth</th>\n",
              "      <th>tfidf_youtub</th>\n",
              "      <th>tfidf_youv</th>\n",
              "      <th>tfidf_zealand</th>\n",
              "      <th>tfidf_zelenskiy</th>\n",
              "      <th>tfidf_zero</th>\n",
              "      <th>tfidf_zone</th>\n",
              "      <th>tfidf_zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>orchard offer bounti appl autumn last year wen...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>born bologna either 1639 1643 sourc conflict a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>victoria embank central london bench overlook ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>letizia battaglia took pictur distanc punch ca...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Life and style</td>\n",
              "      <td>mexico love pork well document countri influen...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5002 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07f87f5d-5ecf-4e13-b5b7-c0e363ec9e20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07f87f5d-5ecf-4e13-b5b7-c0e363ec9e20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07f87f5d-5ecf-4e13-b5b7-c0e363ec9e20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a36d27e7-051d-4867-bde0-3c9e48bfd85b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a36d27e7-051d-4867-bde0-3c9e48bfd85b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a36d27e7-051d-4867-bde0-3c9e48bfd85b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, apply the regressions on both and count vectorized and the td-idf vectorized"
      ],
      "metadata": {
        "id": "-qZzbMxSSxxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "# File paths for Count Vectorized and TF-IDF Vectorized datasets\n",
        "file_paths = {\n",
        "    'Count Vectorized': 'guardian_articles_count.csv',\n",
        "    'TF-IDF Vectorized': 'guardian_articles_tfidf.csv'\n",
        "}\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Step 1: Drop the 'content' column and label encode the 'category' column in each dataset file\n",
        "for vectorization_type, file_path in file_paths.items():\n",
        "    print(f\"Processing {vectorization_type} dataset for initial cleanup...\")\n",
        "\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Drop rows with missing values\n",
        "    data = data.dropna()\n",
        "\n",
        "    # Drop the 'content' column\n",
        "    data = data.drop(columns=['content'])\n",
        "\n",
        "    # Apply label encoding to the 'category' column\n",
        "    data['category'] = le.fit_transform(data['category'])\n",
        "\n",
        "    # Save the updated DataFrame back to the same file\n",
        "    data.to_csv(file_path, index=False)\n",
        "\n",
        "    # Optional: Save the mapping of label encoding for future reference\n",
        "    label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "    print(f\"Initial processing completed for {vectorization_type} dataset.\")\n",
        "    print(f\"Category Label Mapping for {vectorization_type}: {label_mapping}\\n\")\n",
        "\n",
        "# Step 2: Define the models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'k-NN': KNeighborsClassifier(),\n",
        "    'Neural Network': MLPClassifier(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'SGD Classifier': SGDClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier()\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store all evaluation results\n",
        "all_results = {}\n",
        "\n",
        "# Step 3: Loop through each dataset and evaluate models\n",
        "for vectorization_type, file_path in file_paths.items():\n",
        "    print(f\"\\nProcessing dataset: {vectorization_type}\")\n",
        "\n",
        "    # Load the cleaned dataset without the 'content' column\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Prepare the data for training\n",
        "    X = data.drop(columns=['category'])  # Feature columns\n",
        "    y = data['category']  # Encoded category labels\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Dictionary to store results for the current vectorization type\n",
        "    evaluation_results = {}\n",
        "\n",
        "    # Step 4: Train, predict, and evaluate each model\n",
        "    for model_name, model in tqdm(models.items(), desc=f\"Training models on {vectorization_type}\"):\n",
        "        print(f\"Training and evaluating model: {model_name}\")\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict the labels\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        metrics = {}\n",
        "        metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
        "        metrics['Precision'] = precision_score(y_test, y_pred, average='weighted')\n",
        "        metrics['Recall'] = recall_score(y_test, y_pred, average='weighted')\n",
        "        metrics['F1 Score'] = f1_score(y_test, y_pred, average='weighted')\n",
        "        metrics['Confusion Matrix'] = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # ROC-AUC score (only available for certain models)\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_proba = model.predict_proba(X_test)\n",
        "            metrics['ROC-AUC'] = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
        "        else:\n",
        "            metrics['ROC-AUC'] = None\n",
        "\n",
        "        # Store the results\n",
        "        evaluation_results[model_name] = metrics\n",
        "\n",
        "    # Add the evaluation results to the main results dictionary\n",
        "    all_results[vectorization_type] = evaluation_results\n",
        "\n",
        "# Step 5: Print all evaluation results in a clear format\n",
        "for vectorization_type, results in all_results.items():\n",
        "    print(f\"\\n\\n=== Evaluation Results for {vectorization_type} Dataset ===\\n\")\n",
        "\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"\\nModel: {model_name}\")\n",
        "        print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "        print(f\"Precision: {metrics['Precision']:.4f}\")\n",
        "        print(f\"Recall: {metrics['Recall']:.4f}\")\n",
        "        print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
        "\n",
        "        if metrics['ROC-AUC'] is not None:\n",
        "            print(f\"ROC-AUC: {metrics['ROC-AUC']:.4f}\")\n",
        "        else:\n",
        "            print(\"ROC-AUC: Not available for this model\")\n",
        "\n",
        "        print(f\"Confusion Matrix:\\n{metrics['Confusion Matrix']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhaPng70S7h8",
        "outputId": "97a46e58-c70d-4f90-da06-e958d14544b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Count Vectorized dataset for initial cleanup...\n",
            "Initial processing completed for Count Vectorized dataset.\n",
            "Category Label Mapping for Count Vectorized: {'Art and design': 0, 'Books': 1, 'Film': 2, 'Games': 3, 'Law': 4, 'Life and style': 5, 'Travel': 6}\n",
            "\n",
            "Processing TF-IDF Vectorized dataset for initial cleanup...\n",
            "Initial processing completed for TF-IDF Vectorized dataset.\n",
            "Category Label Mapping for TF-IDF Vectorized: {'Art and design': 0, 'Books': 1, 'Film': 2, 'Games': 3, 'Law': 4, 'Life and style': 5, 'Travel': 6}\n",
            "\n",
            "\n",
            "Processing dataset: Count Vectorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  10%|█         | 1/10 [00:47<07:05, 47.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  20%|██        | 2/10 [00:59<03:31, 26.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Naive Bayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  30%|███       | 3/10 [00:59<01:42, 14.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  40%|████      | 4/10 [09:46<21:41, 216.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Gradient Boosting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  50%|█████     | 5/10 [14:42<20:27, 245.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: k-NN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  60%|██████    | 6/10 [14:52<11:00, 165.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Neural Network\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  70%|███████   | 7/10 [15:42<06:23, 127.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Decision Tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  80%|████████  | 8/10 [15:48<02:57, 88.93s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: SGD Classifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on Count Vectorized:  90%|█████████ | 9/10 [15:59<01:04, 64.67s/it]/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: AdaBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training models on Count Vectorized: 100%|██████████| 10/10 [16:16<00:00, 97.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing dataset: TF-IDF Vectorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  10%|█         | 1/10 [00:14<02:14, 14.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  20%|██        | 2/10 [00:28<01:52, 14.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Naive Bayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  30%|███       | 3/10 [00:28<00:54,  7.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  40%|████      | 4/10 [11:35<26:47, 267.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Gradient Boosting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  50%|█████     | 5/10 [22:03<33:08, 397.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: k-NN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  60%|██████    | 6/10 [22:12<17:43, 265.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Neural Network\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  70%|███████   | 7/10 [24:30<11:11, 223.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: Decision Tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  80%|████████  | 8/10 [24:39<05:10, 155.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: SGD Classifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining models on TF-IDF Vectorized:  90%|█████████ | 9/10 [24:46<01:49, 109.22s/it]/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating model: AdaBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training models on TF-IDF Vectorized: 100%|██████████| 10/10 [25:11<00:00, 151.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== Evaluation Results for Count Vectorized Dataset ===\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.7281\n",
            "Precision: 0.7280\n",
            "Recall: 0.7281\n",
            "F1 Score: 0.7280\n",
            "ROC-AUC: 0.9262\n",
            "Confusion Matrix:\n",
            "[[184  14  11  11   9  45  11]\n",
            " [ 15 242   8  12   6  17  11]\n",
            " [ 13   6 231   6   3  22   8]\n",
            " [  8   1   5 235   8  20  17]\n",
            " [  9   6   4   7 263  18  12]\n",
            " [ 47  25  29  16  16 154  22]\n",
            " [  6  10   5  15   6  29 215]]\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.7430\n",
            "Precision: 0.7359\n",
            "Recall: 0.7430\n",
            "F1 Score: 0.7328\n",
            "ROC-AUC: 0.9351\n",
            "Confusion Matrix:\n",
            "[[183  10  15  21  19  30   7]\n",
            " [ 12 249   8  15  10  11   6]\n",
            " [  8   6 248   2   6  13   6]\n",
            " [  1   4   8 260   7   7   7]\n",
            " [  1   4   6   6 289   8   5]\n",
            " [ 36  28  39  31  26 121  28]\n",
            " [  5  13   6  22  25  10 205]]\n",
            "\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 0.6579\n",
            "Precision: 0.6513\n",
            "Recall: 0.6579\n",
            "F1 Score: 0.6481\n",
            "ROC-AUC: 0.8864\n",
            "Confusion Matrix:\n",
            "[[162  14  16  25  22  36  10]\n",
            " [ 10 221  15  18  23  14  10]\n",
            " [ 12   8 239   1  10  16   3]\n",
            " [  4   5  13 225  18  14  15]\n",
            " [  4   2   6   6 273   9  19]\n",
            " [ 25  30  51  36  28 106  33]\n",
            " [ 10  13   9  25  43  35 151]]\n",
            "\n",
            "\n",
            "Model: SVM\n",
            "Accuracy: 0.7301\n",
            "Precision: 0.7491\n",
            "Recall: 0.7301\n",
            "F1 Score: 0.7358\n",
            "ROC-AUC: 0.9364\n",
            "Confusion Matrix:\n",
            "[[174   3  10  19   8  63   8]\n",
            " [ 11 237   8  13   6  29   7]\n",
            " [ 11   3 225   2   6  38   4]\n",
            " [  8   2   2 236   4  34   8]\n",
            " [ 16   2   4   3 268  21   5]\n",
            " [ 30  15  21  20  15 196  12]\n",
            " [ 11   8   5  17  11  42 192]]\n",
            "\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 0.7807\n",
            "Precision: 0.7795\n",
            "Recall: 0.7807\n",
            "F1 Score: 0.7789\n",
            "ROC-AUC: 0.9549\n",
            "Confusion Matrix:\n",
            "[[193   5  15  18   9  39   6]\n",
            " [ 10 250   9  11   6  16   9]\n",
            " [  6   6 253   3   2  14   5]\n",
            " [  2   4   4 259   9   7   9]\n",
            " [  3   1   3   4 273  24  11]\n",
            " [ 31  21  27  27  10 174  19]\n",
            " [  7   7   6   9   6  19 232]]\n",
            "\n",
            "\n",
            "Model: k-NN\n",
            "Accuracy: 0.4873\n",
            "Precision: 0.5469\n",
            "Recall: 0.4873\n",
            "F1 Score: 0.4789\n",
            "ROC-AUC: 0.7880\n",
            "Confusion Matrix:\n",
            "[[179  35  17  20   8  18   8]\n",
            " [ 50 219  15   7   1  13   6]\n",
            " [ 37  60 173   6   5   4   4]\n",
            " [ 30  61   8 180   3   5   7]\n",
            " [ 43  89  26   5 133  11  12]\n",
            " [ 86  85  39  20   8  52  19]\n",
            " [ 57  75  28  13  11  18  84]]\n",
            "\n",
            "\n",
            "Model: Neural Network\n",
            "Accuracy: 0.7219\n",
            "Precision: 0.7216\n",
            "Recall: 0.7219\n",
            "F1 Score: 0.7209\n",
            "ROC-AUC: 0.9245\n",
            "Confusion Matrix:\n",
            "[[175  11  18  15  10  42  14]\n",
            " [ 11 237  10  13   6  21  13]\n",
            " [ 12   3 244   4   2  15   9]\n",
            " [  2   2   9 235   9  22  15]\n",
            " [  8   2   5   6 263  19  16]\n",
            " [ 40  24  31  23  14 154  23]\n",
            " [  8   8   4  19  12  32 203]]\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.6808\n",
            "Precision: 0.6781\n",
            "Recall: 0.6808\n",
            "F1 Score: 0.6793\n",
            "ROC-AUC: 0.8190\n",
            "Confusion Matrix:\n",
            "[[162  18  20  21   7  44  13]\n",
            " [ 17 230   9   8   9  28  10]\n",
            " [ 17  13 212   3   5  30   9]\n",
            " [ 16   8   5 223  11  19  12]\n",
            " [ 14   3   8   3 258  13  20]\n",
            " [ 48  25  38  20  19 131  28]\n",
            " [  7  16   6  12  13  23 209]]\n",
            "\n",
            "\n",
            "Model: SGD Classifier\n",
            "Accuracy: 0.6985\n",
            "Precision: 0.7052\n",
            "Recall: 0.6985\n",
            "F1 Score: 0.6989\n",
            "ROC-AUC: Not available for this model\n",
            "Confusion Matrix:\n",
            "[[166  10  16  15  10  40  28]\n",
            " [ 11 223  12  11   7  18  29]\n",
            " [ 11   3 227   7   4  18  19]\n",
            " [ 12   3   6 219   8  24  22]\n",
            " [  5   6   7   8 252  21  20]\n",
            " [ 37  19  32  20  11 151  39]\n",
            " [  5  12   4  10   5  26 224]]\n",
            "\n",
            "\n",
            "Model: AdaBoost\n",
            "Accuracy: 0.7224\n",
            "Precision: 0.7202\n",
            "Recall: 0.7224\n",
            "F1 Score: 0.7203\n",
            "ROC-AUC: 0.8938\n",
            "Confusion Matrix:\n",
            "[[184  16  17  18  10  36   4]\n",
            " [ 14 228   9   9  12  30   9]\n",
            " [  7   4 246   2   3  22   5]\n",
            " [  6  10   1 250   7  16   4]\n",
            " [  8   3   5   3 256  32  12]\n",
            " [ 37  34  31  32  16 138  21]\n",
            " [  7   9   7  18  13  22 210]]\n",
            "\n",
            "\n",
            "\n",
            "=== Evaluation Results for TF-IDF Vectorized Dataset ===\n",
            "\n",
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.7592\n",
            "Precision: 0.7601\n",
            "Recall: 0.7592\n",
            "F1 Score: 0.7581\n",
            "ROC-AUC: 0.9477\n",
            "Confusion Matrix:\n",
            "[[179   7  10  18  11  49  11]\n",
            " [ 10 248   9  11   5  19   9]\n",
            " [  9   8 245   1   5  16   5]\n",
            " [  3   3   3 251   7  17  10]\n",
            " [  4   1   5   5 284  12   8]\n",
            " [ 25  19  23  23  15 183  21]\n",
            " [  9   7   5  17  18  31 199]]\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.7530\n",
            "Precision: 0.7480\n",
            "Recall: 0.7530\n",
            "F1 Score: 0.7427\n",
            "ROC-AUC: 0.9345\n",
            "Confusion Matrix:\n",
            "[[186  15  14  21  15  26   8]\n",
            " [ 12 248  11  15  10   6   9]\n",
            " [  8   5 253   3   4  10   6]\n",
            " [  3   4   5 263   9   3   7]\n",
            " [  2   5   5   5 291   8   3]\n",
            " [ 37  28  39  25  24 126  30]\n",
            " [  6   7   9  22  25   8 209]]\n",
            "\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 0.6651\n",
            "Precision: 0.6655\n",
            "Recall: 0.6651\n",
            "F1 Score: 0.6529\n",
            "ROC-AUC: 0.9061\n",
            "Confusion Matrix:\n",
            "[[161  12  16  28  27  30  11]\n",
            " [ 13 216  15  18  30   9  10]\n",
            " [ 13   7 236   1  19   8   5]\n",
            " [  2   4  12 234  22  10  10]\n",
            " [  4   2   5   6 286   5  11]\n",
            " [ 23  27  46  37  41 102  33]\n",
            " [ 10  11  11  26  51  20 157]]\n",
            "\n",
            "\n",
            "Model: SVM\n",
            "Accuracy: 0.7434\n",
            "Precision: 0.7509\n",
            "Recall: 0.7434\n",
            "F1 Score: 0.7441\n",
            "ROC-AUC: 0.9372\n",
            "Confusion Matrix:\n",
            "[[168   7   8  18  13  58  13]\n",
            " [  9 242   6  11   6  29   8]\n",
            " [ 10   5 236   1   6  25   6]\n",
            " [  3   2   2 249   7  20  11]\n",
            " [  2   3   3   5 283  16   7]\n",
            " [ 22  19  23  23  14 186  22]\n",
            " [  9   7   4  19  20  35 192]]\n",
            "\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 0.7926\n",
            "Precision: 0.7898\n",
            "Recall: 0.7926\n",
            "F1 Score: 0.7902\n",
            "ROC-AUC: 0.9590\n",
            "Confusion Matrix:\n",
            "[[195   8  12  19  10  35   6]\n",
            " [  8 257   7   9   6  16   8]\n",
            " [  3   6 259   3   2  12   4]\n",
            " [  3   3   3 259  10   8   8]\n",
            " [  7   3   3   2 277  19   8]\n",
            " [ 33  23  28  23  12 175  15]\n",
            " [  5   6   4   9   5  20 237]]\n",
            "\n",
            "\n",
            "Model: k-NN\n",
            "Accuracy: 0.6135\n",
            "Precision: 0.6007\n",
            "Recall: 0.6135\n",
            "F1 Score: 0.5998\n",
            "ROC-AUC: 0.8500\n",
            "Confusion Matrix:\n",
            "[[169  21  17  22  17  21  18]\n",
            " [ 17 220  12  17  21  14  10]\n",
            " [ 28  22 190   3  20  18   8]\n",
            " [ 13   7  10 234  10  10  10]\n",
            " [ 21   9   9   9 239  10  22]\n",
            " [ 53  60  30  35  32  68  31]\n",
            " [ 25  22   4  20  34  17 164]]\n",
            "\n",
            "\n",
            "Model: Neural Network\n",
            "Accuracy: 0.7071\n",
            "Precision: 0.7055\n",
            "Recall: 0.7071\n",
            "F1 Score: 0.7061\n",
            "ROC-AUC: 0.9237\n",
            "Confusion Matrix:\n",
            "[[177  13  18  13  10  37  17]\n",
            " [ 10 237  13   9   8  24  10]\n",
            " [ 20   8 225   2   6  18  10]\n",
            " [  6   4   7 228   9  23  17]\n",
            " [ 12   4   3   3 269  16  12]\n",
            " [ 50  30  21  18  19 147  24]\n",
            " [ 12   8   4  15  19  31 197]]\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.6875\n",
            "Precision: 0.6906\n",
            "Recall: 0.6875\n",
            "F1 Score: 0.6889\n",
            "ROC-AUC: 0.8224\n",
            "Confusion Matrix:\n",
            "[[174  18  16  16   7  44  10]\n",
            " [ 21 222  10  10   5  28  15]\n",
            " [ 17  11 210   9   5  29   8]\n",
            " [  7   5   5 227  14  24  12]\n",
            " [ 12   2   7   2 256  30  10]\n",
            " [ 47  27  29  17  13 147  29]\n",
            " [  7  17   6  13  13  27 203]]\n",
            "\n",
            "\n",
            "Model: SGD Classifier\n",
            "Accuracy: 0.7501\n",
            "Precision: 0.7453\n",
            "Recall: 0.7501\n",
            "F1 Score: 0.7466\n",
            "ROC-AUC: Not available for this model\n",
            "Confusion Matrix:\n",
            "[[194  12  12  15  13  27  12]\n",
            " [ 10 249   7  12   8  17   8]\n",
            " [ 10   5 245   3   6  13   7]\n",
            " [  7   3   4 244  10  14  12]\n",
            " [  6   3   4   7 279  13   7]\n",
            " [ 48  24  27  22  16 151  21]\n",
            " [ 12   6   4  13  18  25 208]]\n",
            "\n",
            "\n",
            "Model: AdaBoost\n",
            "Accuracy: 0.7105\n",
            "Precision: 0.7279\n",
            "Recall: 0.7105\n",
            "F1 Score: 0.7133\n",
            "ROC-AUC: 0.8967\n",
            "Confusion Matrix:\n",
            "[[150  16  17  17  12  65   8]\n",
            " [  5 234  11   8  11  32  10]\n",
            " [  3   1 253   4   1  21   6]\n",
            " [  1   4   3 228  11  40   7]\n",
            " [  2   3   3   2 273  33   3]\n",
            " [ 32  34  31  20  19 159  14]\n",
            " [  1  14   8   4  16  53 190]]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}